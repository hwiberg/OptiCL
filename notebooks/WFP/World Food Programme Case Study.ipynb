{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cfa28f2",
   "metadata": {},
   "source": [
    "# Optimization with Constraint Learning: A WFP case study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b78d69",
   "metadata": {},
   "source": [
    "## The Palatable Diet Problem  \n",
    "\n",
    "<font size=\"4\"> Problem Description</font>    \n",
    "\n",
    "In this case study, we focus on the diet problem related to [(Peters et al., 2021)](https://pubsonline.informs.org/doi/10.1287/ijoo.2019.0047) which seeks to optimize humanitarian food aid. The model formulated by [Peters et al. (2021)](https://pubsonline.informs.org/doi/10.1287/ijoo.2019.0047) aims to provide the World Food Programme (WFP) with a decision-making tool for long-term recovery operations, which simultaneously optimizes the food basket to be delivered, the sourcing plan, the delivery plan, and the transfer modality of a month-long food supply. The model proposed by [Peters et al. (2021)](https://pubsonline.informs.org/doi/10.1287/ijoo.2019.0047) enforces that the food baskets address the nutrient gap and are palatable. To guarantee a certain level of palatability, the authors use a number of “unwritten rules” that have been defined in collaboration with nutrition experts. \n",
    "\n",
    "<div>\n",
    "<img src=\"figures/supplychain_0.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "In this case study, we restrict the model to the diet problem and we take a step further by inferring palatability constraints directly from data that reflects local people's opinions. The conceptual model presents a linear optimization (LO) structure with only the food palatability constraint to be learned. Data on palatability is generated through a simulator, but the procedure would remain unchanged if data were collected in the field, for example through surveys. The structure of this problem, which is an LO and involves only one learned constraint, allows the following analyses: (1) the effect of the trust-region on the optimal solution, and (2) the effect of multiple learned models to define the same constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ef590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Optimization with Constraint Leagning package\n",
    "import opticl\n",
    "\n",
    "# Optimization modelling\n",
    "from pyomo import environ\n",
    "from pyomo.environ import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc48e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea8c06",
   "metadata": {},
   "source": [
    "### Food Basket Palatability  \n",
    "Based on [(Peters et al., 2021)](https://pubsonline.informs.org/doi/10.1287/ijoo.2019.0047), a food basket is defined by 25 foods (e.g., beans, meat, oil) and their relative amount in grams. Each food belongs to one of the five macro-categories: cereals and grains, pulses and vegetables, oils and fats, mixed and blended foods, meat and fish and dairy. For each macro-category $g \\in \\mathcal{G}$ an upper and lower bound are defined, respectively $max_g$ and $min_g$. While in [(Peters et al., 2021)](https://pubsonline.informs.org/doi/10.1287/ijoo.2019.0047), the authors use bound constraints to ensure the food basket palatability, we extend the definition of palatability by mean of a (non-negative) palatability score that is closer to zero for more palatable diets. The score is defined as  \n",
    "\\begin{align}\n",
    "Palatability\\ Score = \\sqrt{\\sum_{g\\in \\mathcal{G}}(\\gamma_{g}(\\widehat{x}_{g}-Opt_{g}))^{2}},\\label{eqn:palatability_score}\n",
    "\\end{align}\n",
    "where\n",
    "$$ \\widehat{x}_{g} = \\sum_{k \\in \\mathcal{K}_g} x_{k} ~~ \\text{with} \\ g \\in \\mathcal{G} \\text{ and}$$\n",
    "$$ Opt_{g} = \\frac{max_{g} + min_{g}}{2} ~~ \\text{with} \\ g \\in \\mathcal{G}.\n",
    "$$\n",
    "\n",
    "Since different macro-categories have different range sizes ($max_g - min_g$), a parameter $\\gamma_{g}$ is used to scale their impact on the score, see Table 1. \n",
    "\n",
    "<br/>\n",
    "<div>\n",
    "<img src=\"figures/table.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "The palatability score is afterwards normalized in a [0,1] interval and subtracted to 1 in order to obtain a value closer to 1 for more palatable diets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d347e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(y):\n",
    "    # Values based on the dataset before normalization\n",
    "    minimum = 71.969 \n",
    "    maximum = 444.847  \n",
    "    return 1 - (y - minimum)/(maximum - minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7654d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_violation(threshold, solution):\n",
    "    # Cereals & Grains\n",
    "    group1 = [1, 11, 12, 14, 15, 22, 23]\n",
    "    group1_names = [list(solution.keys())[i] for i in group1]\n",
    "    values1 = [solution[x] for x in group1_names]\n",
    "    food_in_group1 = sum(values1)*100\n",
    "    idealG1 = 400\n",
    "    distG1 = food_in_group1 - idealG1\n",
    "    \n",
    "    # Pulses & Vegetables\n",
    "    group2 = [0, 6, 10, 13]\n",
    "    group2_names = [list(solution.keys())[i] for i in group2]\n",
    "    values2 = [solution[x] for x in group2_names]\n",
    "    food_in_group2 = sum(values2)*100\n",
    "    idealG2 = 65\n",
    "    distG2 = food_in_group2 - idealG2\n",
    "    \n",
    "    # Oils & Fats\n",
    "    group3 = [21]\n",
    "    group3_names = [list(solution.keys())[i] for i in group3]\n",
    "    values3 = [solution[x] for x in group3_names]\n",
    "    food_in_group3 = sum(values3)*100\n",
    "    idealG3 = 27.5\n",
    "    distG3 = food_in_group3 - idealG3\n",
    "    \n",
    "    # Mixed & Blended Foods\n",
    "    group4 = [5, 24, 16, 17, 18, 19]\n",
    "    group4_names = [list(solution.keys())[i] for i in group4]\n",
    "    values4 = [solution[x] for x in group4_names]\n",
    "    food_in_group4 = sum(values4)*100\n",
    "    idealG4 = 45\n",
    "    distG4 = food_in_group4 - idealG4\n",
    "    \n",
    "    # Meat & Fish & Dairy\n",
    "    group5 = [2, 3, 4, 7, 8]\n",
    "    group5_names = [list(solution.keys())[i] for i in group5]\n",
    "    values5 = [solution[x] for x in group5_names]\n",
    "    food_in_group5 = sum(values5)*100\n",
    "    idealG5 = 30\n",
    "    distG5 = food_in_group5 - idealG5\n",
    "    \n",
    "    real_palatability = np.round(math.sqrt(distG1 ** 2 + (5.7 * distG2) ** 2 + (16 * distG3) ** 2\n",
    "                                      + (4.4 * distG4) ** 2 + (6.6 * distG5) ** 2), 3)\n",
    "    real_palatability_norm = normalize(real_palatability)\n",
    "    return 1-int(real_palatability_norm>=threshold), real_palatability_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1643b77",
   "metadata": {},
   "source": [
    "## Step 1: Conceptual model  \n",
    "\n",
    "**Objective function:** minimize the total cost of the food basket.  \n",
    "\\begin{align}\\min_{\\boldsymbol{x}, y} \\boldsymbol{c}^\\top \\boldsymbol{x}\\end{align}\n",
    "\n",
    "*subject to* \n",
    "\n",
    "**Nutritional constraints:** for each nutrient $j\\in\\mathcal{N}$, at least meet the minimum required level.  \n",
    "\\begin{align} \\sum_{k \\in \\mathcal{K}} nutval_{kj} x_{k} \\geq nutreq_{j}, \\ \\ \\ \\forall l\\in\\mathcal{N},\\end{align}\n",
    "**Constraints on sugar and salt:**</font>  \n",
    "\\begin{align} x_{salt} = 5,\\end{align}   \n",
    "\\begin{align} x_{sugar} = 20,\\end{align} \n",
    "<span style=\"color:blue\">**Palatability constraints:**</span> the food basket palatability has to be at least equal to $t$.  \n",
    "\\begin{align} y \\geq t,\\end{align}  \n",
    "<span style=\"color:blue\">**Learned predictive model:**</span>. the palatability is defined using a predictive model.  \n",
    "\\begin{align} y = \\hat{h}(\\boldsymbol{x}),\\end{align} \n",
    "**Non negativity constraints:**  \n",
    "\\begin{align} x_{k} \\geq 0, \\ \\ \\ \\forall k \\in \\mathcal{K}.\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06499df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_conceptual_model(cost_p):\n",
    "    N = list(nutr_val.index)  # foods\n",
    "    M = nutr_req.columns  # nutrient requirements\n",
    "    model = ConcreteModel('TPDP')\n",
    "    '''\n",
    "    Decision variables\n",
    "    '''\n",
    "    model.x = Var(N, domain=NonNegativeReals)  # variables controlling the food basket\n",
    "    '''\n",
    "    Objective function.\n",
    "    '''\n",
    "    def obj_function(model):\n",
    "        return sum(cost_p[food].item()*model.x[food] for food in N)\n",
    "    model.OBJ = Objective(rule=obj_function, sense=minimize)\n",
    "    '''\n",
    "    Nutrients requirements constraint.\n",
    "    '''\n",
    "    def constraint_rule1(model, req):\n",
    "        return sum(model.x[food] * nutr_val.loc[food, req] for food in N) >= nutr_req[req].item()\n",
    "    model.Constraint1 = Constraint(M, rule=constraint_rule1)\n",
    "    '''\n",
    "    Sugar constraint\n",
    "    '''\n",
    "    def constraint_rule2(model):\n",
    "        return model.x['Sugar'] == 0.2\n",
    "    model.Constraint2 = Constraint(rule=constraint_rule2)\n",
    "    '''\n",
    "    Salt constraint\n",
    "    '''\n",
    "    def constraint_rule3(model):\n",
    "        return model.x['Salt'] == 0.05\n",
    "    model.Constraint3 = Constraint(rule=constraint_rule3)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586c112",
   "metadata": {},
   "source": [
    "## Step 2: Learn the *palatability* constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be87c9",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b2194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutr_val = pd.read_excel('processed-data/Syria_instance.xlsx', sheet_name='nutr_val', index_col='Food')\n",
    "nutr_req = pd.read_excel('processed-data/Syria_instance.xlsx', sheet_name='nutr_req', index_col='Type')\n",
    "cost_p = pd.read_excel('processed-data/Syria_instance.xlsx', sheet_name='FoodCost', index_col='Supplier').iloc[0,:]\n",
    "dataset = pd.read_csv('processed-data/WFP_dataset.csv').sample(frac=1)\n",
    "\n",
    "y = dataset['label']\n",
    "X = dataset.drop(['label'], axis=1, inplace=False)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6da7d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beans</th>\n",
       "      <th>Bulgur</th>\n",
       "      <th>Cheese</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Meat</th>\n",
       "      <th>CSB</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DSM</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Salt</th>\n",
       "      <th>...</th>\n",
       "      <th>Soya-fortified bulgur wheat</th>\n",
       "      <th>Soya-fortified maize meal</th>\n",
       "      <th>Soya-fortified sorghum grits</th>\n",
       "      <th>Soya-fortified wheat flour</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Oil</th>\n",
       "      <th>Wheat</th>\n",
       "      <th>Wheat flour</th>\n",
       "      <th>WSB</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.687675</td>\n",
       "      <td>1.257354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.357429</td>\n",
       "      <td>2.823603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637964</td>\n",
       "      <td>0.715428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>0.551125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.392274</td>\n",
       "      <td>2.540599</td>\n",
       "      <td>3.414615</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>0.292719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>0.701614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.221908</td>\n",
       "      <td>0.336647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545864</td>\n",
       "      <td>0.816616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.832166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626751</td>\n",
       "      <td>0.278648</td>\n",
       "      <td>0.132718</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.311117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694007</td>\n",
       "      <td>0.794680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.039754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.160220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788790</td>\n",
       "      <td>0.261417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.743757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.181913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>0.779749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.178567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.293570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>0.668713</td>\n",
       "      <td>3.322546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.271382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189249</td>\n",
       "      <td>0.813417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0.460621</td>\n",
       "      <td>1.464405</td>\n",
       "      <td>0.160834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.757835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0.929024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.259267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.217787</td>\n",
       "      <td>0.647243</td>\n",
       "      <td>0.647392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Beans    Bulgur    Cheese  Fish  Meat       CSB     Dates       DSM  \\\n",
       "398   0.687675  1.257354  0.000000   0.0   0.0  0.000000  0.000000  0.302104   \n",
       "3833  0.551125  0.000000  0.000000   0.0   0.0  0.000000  0.000000  0.117990   \n",
       "4836  0.701614  0.000000  0.000000   0.0   0.0  0.094990  0.000000  0.330808   \n",
       "4572  0.000000  3.832166  0.000000   0.0   0.0  0.000000  0.626751  0.278648   \n",
       "636   0.039754  0.000000  0.344293   0.0   0.0  0.000000  0.000000  0.106482   \n",
       "...        ...       ...       ...   ...   ...       ...       ...       ...   \n",
       "4931  0.743757  0.000000  0.115426   0.0   0.0  0.700000  0.000000  0.479955   \n",
       "3264  0.779749  0.000000  0.075277   0.0   0.0  0.761232  0.000000  0.392905   \n",
       "1653  0.668713  3.322546  0.000000   0.0   0.0  0.429041  0.000000  0.450216   \n",
       "2607  0.460621  1.464405  0.160834   0.0   0.0  0.757835  0.000000  0.391194   \n",
       "2732  0.929024  0.000000  0.000000   0.0   0.0  0.000000  0.000000  0.339896   \n",
       "\n",
       "          Milk  Salt  ...  Soya-fortified bulgur wheat  \\\n",
       "398   0.000000  0.05  ...                          0.0   \n",
       "3833  0.000000  0.05  ...                          0.0   \n",
       "4836  0.000000  0.05  ...                          0.0   \n",
       "4572  0.132718  0.05  ...                          0.0   \n",
       "636   0.000000  0.05  ...                          0.0   \n",
       "...        ...   ...  ...                          ...   \n",
       "4931  0.000000  0.05  ...                          0.0   \n",
       "3264  0.000000  0.05  ...                          0.0   \n",
       "1653  0.000000  0.05  ...                          0.0   \n",
       "2607  0.000000  0.05  ...                          0.0   \n",
       "2732  0.000000  0.05  ...                          0.0   \n",
       "\n",
       "      Soya-fortified maize meal  Soya-fortified sorghum grits  \\\n",
       "398                    0.000000                           0.0   \n",
       "3833                   0.000000                           0.0   \n",
       "4836                   0.000000                           0.0   \n",
       "4572                   0.000000                           0.0   \n",
       "636                    0.000000                           0.0   \n",
       "...                         ...                           ...   \n",
       "4931                   0.041521                           0.0   \n",
       "3264                   0.000000                           0.0   \n",
       "1653                   0.000000                           0.0   \n",
       "2607                   0.000000                           0.0   \n",
       "2732                   0.000000                           0.0   \n",
       "\n",
       "      Soya-fortified wheat flour  Sugar       Oil     Wheat  Wheat flour  \\\n",
       "398                          0.0    0.2  0.357429  2.823603     0.000000   \n",
       "3833                         0.0    0.2  0.392274  2.540599     3.414615   \n",
       "4836                         0.0    0.2  0.221908  0.336647     0.000000   \n",
       "4572                         0.0    0.2  0.311117  0.000000     0.000000   \n",
       "636                          0.0    0.2  0.160220  0.000000     0.000000   \n",
       "...                          ...    ...       ...       ...          ...   \n",
       "4931                         0.0    0.2  0.181913  0.000000     0.000000   \n",
       "3264                         0.0    0.2  0.178567  0.000000     0.000000   \n",
       "1653                         0.0    0.2  0.271382  0.000000     0.000000   \n",
       "2607                         0.0    0.2  0.166244  0.000000     0.000000   \n",
       "2732                         0.0    0.2  0.259267  0.000000     1.217787   \n",
       "\n",
       "           WSB     label  \n",
       "398   0.637964  0.715428  \n",
       "3833  0.733300  0.292719  \n",
       "4836  0.545864  0.816616  \n",
       "4572  0.694007  0.794680  \n",
       "636   0.788790  0.261417  \n",
       "...        ...       ...  \n",
       "4931  0.000000  0.210851  \n",
       "3264  0.029013  0.293570  \n",
       "1653  0.189249  0.813417  \n",
       "2607  0.000000  0.382687  \n",
       "2732  0.647243  0.647392  \n",
       "\n",
       "[5000 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bce692",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f723b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms = {'gbm': None}\n",
      "Bootstrap iterations = 0\n",
      "Violation rule = 0.5\n"
     ]
    }
   ],
   "source": [
    "alg_dict = {'linear': None, 'svm': None, 'cart': None, 'rf': None, 'gbm': None, 'mlp': None}\n",
    "\n",
    "viol_rule = 0.5 # 'average'\n",
    "\n",
    "gr=False\n",
    "bs = 0\n",
    "\n",
    "print(\"Algorithms = %s\" % alg_dict)\n",
    "print(\"Bootstrap iterations = %d\" % bs)\n",
    "print(\"Violation rule = %s\" % str(viol_rule))\n",
    "code_version = 'AAAI-23_WFPexample'\n",
    "\n",
    "version = 'vAAAI-23_WFPexample'\n",
    "outcome = 'palatability'\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09f4b893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning a model for palatability\n",
      "No bootstrap - training on full training data\n",
      "training palatability with gbm\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = gbm, metric = None\n",
      "saving... results/gbm_palatability_trained.pkl\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.004570455119563544\n",
      "Train R2: 0.910193525532487\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.00595551970521792\n",
      "Test R2: 0.8855012914122791\n",
      "\n",
      "Saving the performance...\n",
      "Done!\n",
      "\n",
      "Preparing model master\n",
      "Group method = violation (violation limit = 0.50)\n"
     ]
    }
   ],
   "source": [
    "data = X_train\n",
    "outcome_list = {'palatability': {'lb':threshold, 'ub':None, 'objective_weight':0,'group_models':gr,\n",
    "'task_type': 'continuous', 'alg_list':alg_dict, 'bootstrap_iterations':bs,\n",
    "                                   'X_train':X_train, 'y_train':y_train, 'X_test':X_test, 'y_test':y_test,\n",
    "                                   'dataset_path':'processed-data/WFP_dataset.csv'}}\n",
    "\n",
    "performance = opticl.train_ml_models(outcome_list, version)\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "performance.to_csv('results/%s_performance.csv' % (code_version))\n",
    "\n",
    "columns_df = ['algorithm','iteration','price_matrix']+list(X.columns)+['objective_function', 'real_palat', 'pred_palat', 'violation', 'time']\n",
    "\n",
    "print(\"\\nPreparing model master\")\n",
    "if viol_rule == 'average':\n",
    "    gr_method = 'average'\n",
    "    max_viol = None\n",
    "    print(\"Group method = %s\" % (gr_method))\n",
    "    gr_string = 'average'\n",
    "else: \n",
    "    gr_method = 'violation'\n",
    "    max_viol = float(viol_rule)\n",
    "    print(\"Group method = %s (violation limit = %.2f)\" % (gr_method, max_viol))\n",
    "    gr_string = 'violation_%.2f' % max_viol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb9250",
   "metadata": {},
   "source": [
    "Train and validation scores: roc_auc (binary classification), neg_mean_squared_error (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02547e",
   "metadata": {},
   "source": [
    "### Select fitted models   \n",
    "Select models using aggregated 'performance' table. The models are selected based on the highest *valid_score*, assuming higher scores are better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f3afbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking model\n",
      "No learned objective\n",
      "1 learned constrained outcomes\n",
      "\n",
      "Checking outcome palatability\n",
      "Embedding outcome with single cart model\n",
      "\n",
      "Embedding constraint for palatability.\n",
      "0.5 <= palatability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>objective</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "      <th>features</th>\n",
       "      <th>var_features</th>\n",
       "      <th>contex_features</th>\n",
       "      <th>group_models</th>\n",
       "      <th>group_method</th>\n",
       "      <th>ensemble_weights</th>\n",
       "      <th>max_violation</th>\n",
       "      <th>trust_region</th>\n",
       "      <th>dataset_path</th>\n",
       "      <th>clustering_model</th>\n",
       "      <th>enlargement</th>\n",
       "      <th>SCM_counterfactuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>palatability</th>\n",
       "      <td>{'results/cart/vAAAI-23_WFPexample_palatabilit...</td>\n",
       "      <td>continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...</td>\n",
       "      <td>Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>violation</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>processed-data/WFP_dataset.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>[0]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          model        task  \\\n",
       "palatability  {'results/cart/vAAAI-23_WFPexample_palatabilit...  continuous   \n",
       "\n",
       "             objective   lb    ub  \\\n",
       "palatability         0  0.5  None   \n",
       "\n",
       "                                                       features  \\\n",
       "palatability  Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...   \n",
       "\n",
       "                                                   var_features  \\\n",
       "palatability  Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...   \n",
       "\n",
       "             contex_features group_models group_method ensemble_weights  \\\n",
       "palatability              {}        False    violation             None   \n",
       "\n",
       "             max_violation trust_region                    dataset_path  \\\n",
       "palatability           0.2         True  processed-data/WFP_dataset.csv   \n",
       "\n",
       "             clustering_model enlargement SCM_counterfactuals  \n",
       "palatability             None         [0]                None  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = opticl.initialize_model_master(outcome_list)\n",
    "mm.loc[outcome,'group_method'] = gr_method\n",
    "mm.loc[outcome,'max_violation'] = max_viol\n",
    "mm.loc[outcome, 'trust_region'] = True\n",
    "model_master = opticl.model_selection(mm, performance)\n",
    "\n",
    "if not os.path.exists('experiments'):\n",
    "    print('Creating folder...')\n",
    "    os.makedirs('experiments')\n",
    "model_master.to_csv('experiments/model_master_%s.csv' % (code_version), index = True)\n",
    "\n",
    "opticl.check_model_master(model_master)\n",
    "model_master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48fcfb7",
   "metadata": {},
   "source": [
    "## Step 3: Solve the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6d0f995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating constraints for the trust region using 5000 samples.\n",
      "... Trust region defined.\n",
      "Embedding constraints for palatability\n",
      "Adding single model.\n",
      "GLPSOL: GLPK LP/MIP Solver, v4.65\n",
      "Parameter(s) specified in the command line:\n",
      " --write C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpub33fhvk.glpk.raw --wglp C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpufo20_1v.glpk.glp\n",
      " --cpxlp C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpwtc2pz1q.pyomo.lp\n",
      "Reading problem data from 'C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpwtc2pz1q.pyomo.lp'...\n",
      "C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpwtc2pz1q.pyomo.lp:56007: warning: lower bound of variable 'x27' redefined\n",
      "C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpwtc2pz1q.pyomo.lp:56007: warning: upper bound of variable 'x27' redefined\n",
      "263 rows, 5063 columns, 50122 non-zeros\n",
      "36 integer variables, all of which are binary\n",
      "56043 lines were read\n",
      "Writing problem data to 'C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpufo20_1v.glpk.glp'...\n",
      "60740 lines were written\n",
      "GLPK Integer Optimizer, v4.65\n",
      "263 rows, 5063 columns, 50122 non-zeros\n",
      "36 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "235 constraint coefficient(s) were reduced\n",
      "258 rows, 5059 columns, 50113 non-zeros\n",
      "36 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.200e-05  max|aij| =  5.169e+03  ratio =  4.307e+08\n",
      "GM: min|aij| =  1.136e-02  max|aij| =  8.806e+01  ratio =  7.755e+03\n",
      "EQ: min|aij| =  1.302e-04  max|aij| =  1.000e+00  ratio =  7.682e+03\n",
      "2N: min|aij| =  6.300e-05  max|aij| =  1.746e+00  ratio =  2.771e+04\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 256\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer, v4.65\n",
      "258 rows, 5059 columns, 50113 non-zeros\n",
      "      0: obj =   6.369503388e+03 inf =   4.192e+00 (3)\n",
      "      9: obj =   6.195932872e+03 inf =   1.258e-14 (0)\n",
      "*    79: obj =   3.432674150e+03 inf =   1.264e-14 (0)\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+    79: mip =     not found yet >=              -inf        (1; 0)\n",
      "+   131: >>>>>   3.665833178e+03 >=   3.439003214e+03   6.2% (15; 0)\n",
      "+   142: >>>>>   3.646043266e+03 >=   3.452770649e+03   5.3% (14; 1)\n",
      "+   223: >>>>>   3.509144603e+03 >=   3.499820712e+03   0.3% (4; 11)\n",
      "+   241: mip =   3.509144603e+03 >=     tree is empty   0.0% (0; 29)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n",
      "Time used:   0.3 secs\n",
      "Memory used: 10.0 Mb (10489172 bytes)\n",
      "Writing MIP solution to 'C:\\Users\\dmaragn\\AppData\\Local\\Temp\\tmpub33fhvk.glpk.raw'...\n",
      "5335 lines were written\n"
     ]
    }
   ],
   "source": [
    "start_cm = time.time()\n",
    "conceptual_model= init_conceptual_model(cost_p)\n",
    "cm = time.time() - start_cm\n",
    "\n",
    "start_opticl = time.time()\n",
    "final_model = opticl.optimization_MIP(conceptual_model, model_master)\n",
    "model_opticl = time.time() - start_opticl\n",
    "# final_model.write('experiments/mip_%s_seed_%d.lp' % (code_version, seed))\n",
    "opt = SolverFactory('glpk')\n",
    "start_time = time.time()\n",
    "results = opt.solve(final_model, logfile = \"WFP_logfile.txt\", tee=True) \n",
    "computation_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecfbc0b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63512965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_eval, cm, model_opticl, computation_time):\n",
    "    pred_palat = value(model_eval.y[outcome])\n",
    "    violation_bool, real_palat = check_violation(threshold,  model_eval.x.get_values())\n",
    "    ## Save solutions\n",
    "    solution = {food: str(np.round(model_eval.x.get_values()[food]*100, 2))+' g' for food in model_eval.x.get_values().keys() if np.round(model_eval.x.get_values()[food],2) > 0}\n",
    "\n",
    "    print('\\n################################### Summary ###################################')\n",
    "    print(f'Optimal Solution: {solution}\\n')\n",
    "    print(\"Total cost: %.3f $\" % value(model_eval.OBJ))\n",
    "    print(\"Predicted palatability: %.3f\" % pred_palat)\n",
    "    print(\"Real palatability: %.3f\" % real_palat)\n",
    "\n",
    "    print(f'\\nConceptual model defined in {np.round(cm, 3)} seconds')\n",
    "    if model_master.loc['palatability', 'trust_region']:\n",
    "        print(f'Learned constraints & trust region embedded in {np.round(model_opticl, 3)} seconds')\n",
    "    else:\n",
    "        print(f'Learned constraints embedded in {np.round(model_opticl, 3)} seconds')\n",
    "    print(f'Problem Solved in {np.round(computation_time, 3)} seconds')\n",
    "    print('###############################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8459533a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################### Summary ###################################\n",
      "Optimal Solution: {'Beans': '48.13 g', 'DSM': '1.35 g', 'Milk': '48.09 g', 'Salt': '5.0 g', 'Lentils': '7.69 g', 'Maize': '39.82 g', 'Maize meal': '200.46 g', 'Soya-fortified bulgur wheat': '1.51 g', 'Sugar': '20.0 g', 'Oil': '26.48 g', 'Wheat': '105.45 g', 'WSB': '70.0 g'}\n",
      "\n",
      "Total cost: 3509.145 $\n",
      "Predicted palatability: 0.655\n",
      "Real palatability: 0.683\n",
      "\n",
      "Conceptual model defined in 0.005 seconds\n",
      "Learned constraints & trust region embedded in 1.392 seconds\n",
      "Problem Solved in 0.784 seconds\n",
      "###############################################################################\n"
     ]
    }
   ],
   "source": [
    "evaluation(final_model, cm, model_opticl, computation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16344bb6",
   "metadata": {},
   "source": [
    "## Trust region  \n",
    "\n",
    "As the optimal solutions of optimization problems are often at the extremes of the feasible region, this can be problematic for the validity of the trained ML model. Generally speaking the accuracy of a predictive model deteriorates for points that are further away from the data points in $\\mathcal{D}$ [(Goodfellow et al. 2015)](https://arxiv.org/abs/1412.6572). To mitigate this problem, we elaborate on the idea proposed by [Biggs et al. (2021)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2986630) to use the convex hull (CH) of the dataset as a *trust region* constraint to prevent the predictive model from extrapolating. If $\\boldsymbol{X} = \\{ \\boldsymbol{\\hat{x}}_i \\}_{i=1}^N$ is the set of observed input data with $\\boldsymbol{\\hat{x}}_i = (\\boldsymbol{\\bar{x}}_i, \\boldsymbol{\\bar{w}}_i)$, we define the trust region as the CH of this set and denote it by CH($\\boldsymbol{X}$). Recall that CH($\\boldsymbol{X}$) is the smallest convex polytope that contains the set of points $\\boldsymbol{X}$. It is well-known that computing the CH is exponential in time and space with respect to the number of samples and their dimensionality. However, since the CH is a polytope, explicit expressions for its facets are not necessary. More precisely, CH($\\boldsymbol{X}$) is represented as\n",
    "\\begin{align}\n",
    "    \\text{CH($\\boldsymbol{X}$)} = \\bigg\\{ \\boldsymbol{x} \\bigg| \\sum_{i \\in \\mathcal{I}} \\lambda_i \\boldsymbol{\\hat{x}}_i = \\boldsymbol{x}, \\ \\sum_{i \\in \\mathcal{I}} \\lambda_i = 1, \\ \\boldsymbol{\\lambda} \\geq 0\n",
    "    \\bigg\\},\n",
    "\\label{eqn:trust_region1}\n",
    "\\end{align}\n",
    "where $\\boldsymbol{\\lambda} \\in \\mathbb{R}^N$, and $\\mathcal{I} = \\{1, \\dots, N \\}$ is the index set of samples in \n",
    "$\\boldsymbol{X}$.\n",
    "\n",
    "<br>\n",
    "<font size=\"4\">Extensions</font> \n",
    "\n",
    "**1) Clustering**  \n",
    "In situations such as the left figure in:\n",
    "<div>\n",
    "<img src=\"figures/CTR.jpg\" width=\"9000\"/>\n",
    "</div>\n",
    "CH($\\boldsymbol{X}$) includes regions with few or no data points (low-density regions). Blindly using CH($\\boldsymbol{X}$) in this case can be problematic if the solutions are found in the low-density regions. We therefore advocate the use of a two-step approach. First, clustering is used to identify distinct high-density regions, and then the trust region is represented as the union of the CHs of the individual clusters. The trust region formulation becomes:\n",
    "\n",
    "\\begin{align}\n",
    "    \\bigcup_{k\\in\\mathcal{K}}\\text{CH($\\boldsymbol{X}_k$)} = \\bigg\\{ \\boldsymbol{x}\n",
    "    \\bigg| \\sum_{i \\in \\mathcal{I}_k} \n",
    "    \\lambda_i \\boldsymbol{\\hat{x}}_i = \\boldsymbol{x}, \\ \\sum_{i \\in \\mathcal{I}_k}  \\lambda_i = u_k \\ \\forall k \\in \\mathcal{K}, \\sum_{k \\in \\mathcal{K}} u_k = 1, \\ \\boldsymbol{\\lambda} \\geq 0, \\ \\boldsymbol{u} \\in \\{0,1\\}^{|\\mathcal{K}|}\n",
    "    \\bigg\\},\n",
    "\\label{eqn:trust_region2}\n",
    "\\end{align}\n",
    "where $\\mathcal{K}$ is the set of clusters.  \n",
    "\n",
    "**2) Column selection**  \n",
    "The number of variables used to define the trust region increases with the increase in the dataset size, which may make the optimization process prohibitive when the number of samples becomes too large. We therefore provide a **column selection algorithm** that selects a small subset of the samples. This algorithm can be directly used with convex optimization problems or embedded as part of a branch and bound algorithm when the optimization problem involves integer variables.\n",
    "<div>\n",
    "<img src=\"figures/CSTR.jpg\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "**3) Enlarged Trust region**  \n",
    "Although we introduced the trust region as a set of constraints to preserve the predictive performance of the fitted constraints, in their recent paper, [Balestriero et al. (2021)](https://arxiv.org/abs/2110.09485) show how likely is to extrapolate in a high-dimensional dataset and therefore, how the generalization performance is typically obtained using samples outside the interpolation region. In light of this evidence, we propose an $\\epsilon$-CH formulation which enables the optimal solution to be outside $CH(X)$. The $\\epsilon$-CH is formulated as follows:\n",
    "\\begin{align}\n",
    "\\text{$\\epsilon$-CH($\\boldsymbol{X}$)} = \\bigg\\{ (\\boldsymbol{x},\\boldsymbol{s}) \\bigg| \\sum_{i \\in \\mathcal{I}} \\lambda_i \\boldsymbol{\\hat{x}}_i = \\boldsymbol{x} + \\boldsymbol{s}, \\ \\sum_{i \\in \\mathcal{I}} \\lambda_i = 1, \\ \\boldsymbol{\\lambda} \\geq 0, \\ ||\\boldsymbol{s}||_{p} \\leq \\epsilon\n",
    "    \\bigg\\},\n",
    "\\label{eqn:epstrust_region1} \n",
    "\\end{align}\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/ETR.jpg\" width=\"1000\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004a14f",
   "metadata": {},
   "source": [
    "#### Enlarged trust region\n",
    "[x, , ]-> 0: no enlargement, 1: enlargement  \n",
    "[ ,x, ]-> 0: enlargement using a bounding constraint, 1: enlargement using a penalty term in the objective function  \n",
    "[ , ,x]-> penalty coefficient/upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e4b82be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking model\n",
      "No learned objective\n",
      "1 learned constrained outcomes\n",
      "\n",
      "Checking outcome palatability\n",
      "Embedding outcome with single gbm model\n",
      "\n",
      "Embedding constraint for palatability.\n",
      "0.5 <= palatability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>objective</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "      <th>features</th>\n",
       "      <th>var_features</th>\n",
       "      <th>contex_features</th>\n",
       "      <th>group_models</th>\n",
       "      <th>group_method</th>\n",
       "      <th>ensemble_weights</th>\n",
       "      <th>max_violation</th>\n",
       "      <th>trust_region</th>\n",
       "      <th>dataset_path</th>\n",
       "      <th>clustering_model</th>\n",
       "      <th>enlargement</th>\n",
       "      <th>SCM_counterfactuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>palatability</th>\n",
       "      <td>{'results/gbm/vAAAI-23_WFPexample_palatability...</td>\n",
       "      <td>continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...</td>\n",
       "      <td>Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>violation</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>processed-data/WFP_dataset.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>[1, 0, 0.1]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          model        task  \\\n",
       "palatability  {'results/gbm/vAAAI-23_WFPexample_palatability...  continuous   \n",
       "\n",
       "             objective   lb    ub  \\\n",
       "palatability         0  0.5  None   \n",
       "\n",
       "                                                       features  \\\n",
       "palatability  Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...   \n",
       "\n",
       "                                                   var_features  \\\n",
       "palatability  Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...   \n",
       "\n",
       "             contex_features group_models group_method ensemble_weights  \\\n",
       "palatability              {}        False    violation             None   \n",
       "\n",
       "             max_violation trust_region                    dataset_path  \\\n",
       "palatability           0.5         True  processed-data/WFP_dataset.csv   \n",
       "\n",
       "             clustering_model  enlargement SCM_counterfactuals  \n",
       "palatability             None  [1, 0, 0.1]                None  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = opticl.initialize_model_master(outcome_list)\n",
    "mm.loc[outcome,'group_method'] = gr_method\n",
    "mm.loc[outcome,'max_violation'] = max_viol\n",
    "mm.loc[outcome, 'trust_region'] = True\n",
    "mm.loc[outcome, 'enlargement'] = [1, 0, 0.1]\n",
    "model_master = opticl.model_selection(mm, performance)\n",
    "\n",
    "if not os.path.exists('experiments'):\n",
    "    print('Creating folder...')\n",
    "    os.makedirs('experiments')\n",
    "model_master.to_csv('experiments/model_master_%s.csv' % (code_version), index = True)\n",
    "\n",
    "opticl.check_model_master(model_master)\n",
    "model_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6a6d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating constraints for the trust region using 5000 samples.\n",
      "The l1 norm is used for the enlarged CH trust region\n",
      "The trust region is being enlarged with a constraint upper bounded by: 0.1.\n",
      "... Trust region defined.\n",
      "Embedding constraints for palatability\n",
      "Adding single model.\n",
      "\n",
      "################################### Summary ###################################\n",
      "Optimal Solution: {'Beans': '17.34 g', 'Milk': '42.53 g', 'Salt': '5.0 g', 'Lentils': '30.45 g', 'Maize': '142.24 g', 'Sugar': '20.0 g', 'Oil': '21.81 g', 'Wheat': '221.66 g', 'WSB': '76.45 g'}\n",
      "\n",
      "Total cost: 3314.860 $\n",
      "Predicted palatability: 0.504\n",
      "Real palatability: 0.623\n",
      "\n",
      "Conceptual model defined in 0.008 seconds\n",
      "Learned constraints & trust region embedded in 2.527 seconds\n",
      "Problem Solved in 4.779 seconds\n",
      "###############################################################################\n"
     ]
    }
   ],
   "source": [
    "start_cm = time.time()\n",
    "conceptual_model= init_conceptual_model(cost_p)\n",
    "cm = time.time() - start_cm\n",
    "\n",
    "start_opticl = time.time()\n",
    "model_TR = opticl.optimization_MIP(conceptual_model, model_master)\n",
    "model_opticl = time.time() - start_opticl\n",
    "# final_model.write('experiments/mip_%s_seed_%d.lp' % (code_version, seed))\n",
    "opt = SolverFactory('glpk')\n",
    "start_time = time.time()\n",
    "results = opt.solve(model_TR) \n",
    "computation_time = time.time() - start_time\n",
    "evaluation(model_TR, cm, model_opticl, computation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265ab37",
   "metadata": {},
   "source": [
    "## Robust Constraint Learning\n",
    "\n",
    "There are two sources of uncertainty, and consequently notions of robustness, that can be considered when embedding a trained machine learning model as a constraint.  \n",
    "\n",
    "**Function Uncertainty**. The first source of uncertainty is in the underlying functional form of $\\hat{h}$. We do not know the ground truth relationship between $(\\boldsymbol{x},\\boldsymbol{w})$ and $y$, and there is potential for model mis-specification. We limit this risk through our nonparametric model selection procedure, namely training $\\hat{h}$ for a diverse set of methods (e.g., decision tree, regression, neural network) and selecting the final model using a cross-validation procedure.\n",
    "\n",
    "**Parameter Uncertainty**. Even within a single model class, there is uncertainty in the parameter estimates that define $\\hat{h}$. Consider the case of linear regression. A regression estimator consists of point estimates of coefficients and an intercept term, but there is uncertainty in the estimates as they are derived from noisy data. We seek to make our model robust by using a model-wrapper approach, which is agnostic to the underlying model.\n",
    "\n",
    "<br><br>\n",
    "<font size=\"4\">Model wrapper</font>\n",
    "\n",
    "The model wrapper approach is agnostic to the underlying method. Rather than obtaining our estimated outcome from a single trained predictive model, we suppose that we have $P$ estimators. The set of estimators can be obtained by bootstrapping or by training models using different methods. The uncertainty is thus characterized by different realizations of the predicted value from multiple estimators.  \n",
    "\n",
    "We introduce a constraint that at most $\\alpha \\in [0,1]$ proportion of the $P$ estimators violate the constraint. Let $\\hat{h}_1,\\ldots,\\hat{h}_P$ be the individual estimators. Then $\\hat{h}_i(x) \\leq \\tau$ in at least $1-\\alpha P$ of these estimators. This allows for a degree of robustness to individual model predictions by \\color{blue}{discarding a small number of potential outlier predictions.} Formally,\n",
    "\\begin{align}\n",
    "    \\frac{1}{P}\\sum_{i=1}^P \\mathbb{I} (y_i \\leq \\tau) \\geq 1 - \\alpha. \\label{eqn:model_wrapper}\n",
    "\\end{align}\n",
    "Note that $\\alpha = 0$ enforces the bound for all estimators, yielding the most conservative estimate, whereas $\\alpha = 1$ removes the constraint entirely. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8dbec",
   "metadata": {},
   "source": [
    "<font size=\"4\">OptiCL Specs</font>  \n",
    "- **group_method**: $average$ will constraint the average prediction to be $\\leq \\tau$. $violation$ will allow at most viol_rule (%) ML models to predict about the threshold $\\tau$.\n",
    "- **viol_rule**: percentage of violation.\n",
    "- **bs**: number of ML models.\n",
    "- **ensemble_weights**: weights of different ML models (*not supported yet*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaf585c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms = {'cart': None}\n",
      "Bootstrap iterations = 5\n",
      "Violation rule = 0.2\n"
     ]
    }
   ],
   "source": [
    "alg_dict = {'cart': None}\n",
    "viol_rule = '0.2'\n",
    "\n",
    "### Example with grouping/bootstrap\n",
    "gr=True\n",
    "bs = 5\n",
    "\n",
    "print(\"Algorithms = %s\" % alg_dict)\n",
    "print(\"Bootstrap iterations = %d\" % bs)\n",
    "print(\"Violation rule = %s\" % str(viol_rule))\n",
    "code_version = 'AAAI-23_WFPexample'\n",
    "\n",
    "version = 'vAAAI-23_WFPexample'\n",
    "outcome = 'palatability'\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "426449e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning a model for palatability\n",
      "Bootstrap iteration 1 of 5\n",
      "training palatability_s0 with cart\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "saving... results/cart_palatability_s0_trained.pkl\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.011849332956652487\n",
      "Train R2: 0.7596535401549386\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.014127246086486515\n",
      "Test R2: 0.7284120702429107\n",
      "\n",
      "Bootstrap iteration 2 of 5\n",
      "training palatability_s1 with cart\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "saving... results/cart_palatability_s1_trained.pkl\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.0117955192941538\n",
      "Train R2: 0.7699757356309128\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.015408708341935324\n",
      "Test R2: 0.7037402775834714\n",
      "\n",
      "Bootstrap iteration 3 of 5\n",
      "training palatability_s2 with cart\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "saving... results/cart_palatability_s2_trained.pkl\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.012247712031032356\n",
      "Train R2: 0.758720086997085\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.013630466945960809\n",
      "Test R2: 0.737960641345663\n",
      "\n",
      "Bootstrap iteration 4 of 5\n",
      "training palatability_s3 with cart\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "saving... results/cart_palatability_s3_trained.pkl\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.011322700839432464\n",
      "Train R2: 0.7787131201566092\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.015793678819206357\n",
      "Test R2: 0.6964705556365257\n",
      "\n",
      "Bootstrap iteration 5 of 5\n",
      "training palatability_s4 with cart\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "saving... results/cart_palatability_s4_trained.pkl\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.011550750401589462\n",
      "Train R2: 0.7725559383568736\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.014308102067169443\n",
      "Test R2: 0.7252045103700591\n",
      "\n",
      "Saving the performance...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "outcome_list = {'palatability': {'lb':threshold, 'ub':None, 'objective_weight':0,'group_models':gr,\n",
    "'task_type': 'continuous', 'alg_list':alg_dict, 'bootstrap_iterations':bs,\n",
    "                                   'X_train':X_train, 'y_train':y_train, 'X_test':X_test, 'y_test':y_test,\n",
    "                                   'dataset_path':'processed-data/WFP_dataset.csv'}}\n",
    "\n",
    "performance = opticl.train_ml_models(outcome_list, version)\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "performance.to_csv('results/%s_performance.csv' % (code_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1d826a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing model master\n",
      "Group method = violation (violation limit = 0.20)\n",
      "Checking model\n",
      "No learned objective\n",
      "1 learned constrained outcomes\n",
      "\n",
      "Checking outcome palatability\n",
      "Embedding outcome with ensemble of 5 models, aggregation = violation\n",
      "\n",
      "Embedding constraint for palatability.\n",
      "0.5 <= palatability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>objective</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "      <th>features</th>\n",
       "      <th>var_features</th>\n",
       "      <th>contex_features</th>\n",
       "      <th>group_models</th>\n",
       "      <th>group_method</th>\n",
       "      <th>ensemble_weights</th>\n",
       "      <th>max_violation</th>\n",
       "      <th>trust_region</th>\n",
       "      <th>dataset_path</th>\n",
       "      <th>clustering_model</th>\n",
       "      <th>enlargement</th>\n",
       "      <th>SCM_counterfactuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>palatability</th>\n",
       "      <td>{'results/cart/vAAAI-23_WFPexample_palatabilit...</td>\n",
       "      <td>continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...</td>\n",
       "      <td>Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>violation</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>processed-data/WFP_dataset.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>[0]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          model        task  \\\n",
       "palatability  {'results/cart/vAAAI-23_WFPexample_palatabilit...  continuous   \n",
       "\n",
       "             objective   lb    ub  \\\n",
       "palatability         0  0.5  None   \n",
       "\n",
       "                                                       features  \\\n",
       "palatability  Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...   \n",
       "\n",
       "                                                   var_features  \\\n",
       "palatability  Index(['Beans', 'Bulgur', 'Cheese', 'Fish', 'M...   \n",
       "\n",
       "             contex_features group_models group_method ensemble_weights  \\\n",
       "palatability              {}         True    violation             None   \n",
       "\n",
       "             max_violation trust_region                    dataset_path  \\\n",
       "palatability           0.2         True  processed-data/WFP_dataset.csv   \n",
       "\n",
       "             clustering_model enlargement SCM_counterfactuals  \n",
       "palatability             None         [0]                None  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_df = ['algorithm','iteration','price_matrix']+list(X.columns)+['objective_function', 'real_palat', 'pred_palat', 'violation', 'time']\n",
    "\n",
    "print(\"\\nPreparing model master\")\n",
    "gr_method = None\n",
    "if viol_rule == 'average':\n",
    "    gr_method = 'average'\n",
    "    max_viol = None\n",
    "    print(\"Group method = %s\" % (gr_method))\n",
    "    gr_string = 'average'\n",
    "else: \n",
    "    gr_method = 'violation'\n",
    "    max_viol = float(viol_rule)\n",
    "    print(\"Group method = %s (violation limit = %.2f)\" % (gr_method, max_viol))\n",
    "    gr_string = 'violation_%.2f' % max_viol\n",
    "\n",
    "mm = opticl.initialize_model_master(outcome_list)\n",
    "mm.loc[outcome,'group_method'] = gr_method\n",
    "mm.loc[outcome,'max_violation'] = max_viol\n",
    "mm.loc[outcome, 'trust_region'] = True\n",
    "model_master = opticl.model_selection(mm, performance)\n",
    "\n",
    "if not os.path.exists('experiments'):\n",
    "    print('Creating folder...')\n",
    "    os.makedirs('experiments')\n",
    "model_master.to_csv('experiments/model_master_%s.csv' % (code_version), index = True)\n",
    "\n",
    "opticl.check_model_master(model_master)\n",
    "model_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9fd629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating constraints for the trust region using 5000 samples.\n",
      "... Trust region defined.\n",
      "Embedding constraints for palatability_0\n",
      "Embedding constraints for palatability_1\n",
      "Embedding constraints for palatability_2\n",
      "Embedding constraints for palatability_3\n",
      "Embedding constraints for palatability_4\n",
      "palatability\n",
      "Adding ensemble constraint with 5 models and violation limit = 0.20\n",
      "\n",
      "################################### Summary ###################################\n",
      "Optimal Solution: {'Beans': '48.15 g', 'DSM': '1.85 g', 'Milk': '47.05 g', 'Salt': '5.0 g', 'Lentils': '8.39 g', 'Maize': '50.74 g', 'Maize meal': '186.9 g', 'Soya-fortified bulgur wheat': '1.42 g', 'Sugar': '20.0 g', 'Oil': '26.02 g', 'Wheat': '105.78 g', 'WSB': '70.3 g'}\n",
      "\n",
      "Total cost: 3511.343 $\n",
      "Predicted palatability: 0.582\n",
      "Real palatability: 0.683\n",
      "\n",
      "Conceptual model defined in 0.005 seconds\n",
      "Learned constraints & trust region embedded in 1.755 seconds\n",
      "Problem Solved in 7.621 seconds\n",
      "###############################################################################\n"
     ]
    }
   ],
   "source": [
    "start_cm = time.time()\n",
    "conceptual_model= init_conceptual_model(cost_p)\n",
    "cm = time.time() - start_cm\n",
    "\n",
    "start_opticl = time.time()\n",
    "model_MW = opticl.optimization_MIP(conceptual_model, model_master)\n",
    "model_opticl_time = time.time() - start_opticl\n",
    "# final_model.write('experiments/mip_%s_seed_%d.lp' % (code_version, seed))\n",
    "opt = SolverFactory('glpk')\n",
    "start_time = time.time()\n",
    "results = opt.solve(model_MW) \n",
    "computation_time = time.time() - start_time\n",
    "evaluation(model_MW, cm, model_opticl_time, computation_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
