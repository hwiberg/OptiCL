{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WFP CASE STUDY  \n",
    "Requirements: gurobi license, iai license (not mandatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem description**  \n",
    "In this case study, we use a simplified version of the model proposed by  [Peters et al. (2016)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2880438) which seeks to optimize humanitarian food aid. Its extended version aims to provide the World Food Programme (WFP) with a decision-making tool that simultaneously optimizes the food basket to be delivered, the sourcing plan, the delivery plan, and the transfer modality of a long-term recovery operation for each month in a predefined time horizon. The model proposed by \\cite{peters2021nutritious} enforces that the food baskets address the nutrient gap and are palatable. To guarantee a certain level of palatability, the authors use a number of “unwritten rules” that have been defined in collaboration with nutrition experts. In this case study, we take a step further by inferring palatability constraints directly from data that reflects local people's opinions.\n",
    "\n",
    "**The Model**  \n",
    "The optimization model is a combination of a capacitated, multi-commodity network flow model and a diet model with constraints for nutrition levels and food basket palatability. \n",
    "The set, parameters, and variables used to define the constraints and the objective function are displayed in the following tables:\n",
    "<img src=\"figures/WFPsets.jpg\" alt=\"WFP sets\" width=\"300\"/>\n",
    "<img src=\"figures/WFPparams.jpg\" alt=\"WFP params\" width=\"700\"/>\n",
    "<img src=\"figures/WFPvars.jpg\" alt=\"WFP vars\" width=\"650\"/>\n",
    "\n",
    "$\\min_{x, y, F} \\sum_{i \\in \\mathcal{N_S}} \\sum_{j\\in \\mathcal{N_T \\cup N_D}} \\sum_{k \\in \\mathcal{K}} p_{ik}^PF_{ijk} + \\sum_{i \\in \\mathcal{N_S \\cup N_T}} \\sum_{j \\in \\mathcal{N_T \\cup N_D}} \\sum_{k \\in \\mathcal{K}} p_{ijk}^TF_{ijk}$  \n",
    "\n",
    "*Subject to*  \n",
    "\n",
    "$\\sum_{j \\in \\mathcal{N_T}} F_{ijk} = \\sum_{j \\in \\mathcal{N_T}} F_{jik} \\ \\ \\ \\forall i \\in \\mathcal{N_T}, \\ \\forall k \\in \\mathcal{K},$  \n",
    "$\\sum_{j \\in \\mathcal{N_S \\cup N_T}} \\alpha F_{jik} = d_ix_kdays \\ \\ \\ \\forall i \\in \\mathcal{N_D}, \\ \\forall k \\in \\mathcal{K}$ $ \\sum_{j \\in \\mathcal{N_T \\cup N_D}} F_{ijk} \\leq cap_{ik}^P \\ \\ \\ \\forall i \\in \\mathcal{N_S}, \\ \\forall k \\in \\mathcal{K},$    \n",
    "$ \\sum_{k \\in \\mathcal{K}} Nutval_{kl} x_{k} \\geq Nutreq_{l} \\ \\ \\ \\forall l\\in\\mathcal{L},$  \n",
    "$ x_{salt} = 5,$  \n",
    "$ x_{sugar} = 20,$  \n",
    "$ g(y) \\leq 0,$  \n",
    "$ y = \\hat{h}(x)$    \n",
    "$ F_{ijk}, x_{k} \\geq 0 \\ \\ \\ \\forall i,j \\in  \\mathcal{N}, \\ \\forall k \\in \\mathcal{K}.$  \n",
    "\n",
    "\n",
    "For a detailed description of the model we refer to [TBD et al. (2021)](https://google.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from gurobipy import Model, GRB, quicksum, tupledict\n",
    "from sklearn.utils.extmath import cartesian\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = input(\"Do you have the InterpretableAI license? Y/n: \")\n",
    "if question1.upper() == 'Y':\n",
    "    print('Importing InterpretableAI packages...')\n",
    "    from interpretableai import iai\n",
    "else:\n",
    "    print(\"Optimal trees will not be used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add modules\n",
    "sys.path.append(os.path.abspath('../../src'))  # TODO: has to be changed\n",
    "import ConstraintLearning\n",
    "import embed_mip as em \n",
    "import run_MLmodels as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "**df_fb**: dataframe of food basket instances  \n",
    "**nutr_val**: nutritional values for each of the 25 foods  \n",
    "**nutr_req**: 11 nutrition requirements  \n",
    "**suppliers**: list of supplier nodes  \n",
    "**transshippers**: list of transshipment nodes  \n",
    "**demand**: list of demand nodes  \n",
    "**cost_p**: matrix of procurement costs  \n",
    "**cost_t**: matrix of transportation costs  \n",
    "**nodes**: list of nodes in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutr_req = pd.read_excel('processed-data/Syria_instance.xlsx', sheet_name='nutr_req', index_col='Type')\n",
    "nutr_val = pd.read_excel('processed-data/Syria_instance.xlsx', sheet_name='nutr_val', index_col='Food')\n",
    "demand = pd.read_excel('processed-data\\Syria_instance.xlsx', sheet_name='Demand')\n",
    "suppliers = pd.read_excel('processed-data\\Syria_instance.xlsx', sheet_name='Suppliers')\n",
    "transshippers = pd.read_excel('processed-data\\Syria_instance.xlsx', sheet_name='Transhippers')\n",
    "edges = pd.read_excel('processed-data\\Syria_instance.xlsx', sheet_name='EdgesCost')\n",
    "tcost_matrix = pd.read_excel('processed-data\\Syria_instance.xlsx', sheet_name='EdgesCost')\n",
    "tcost_matrix.drop(['distance', 'duration', 'edge'], axis=1, inplace=True)\n",
    "cost_p = pd.read_excel('processed-data\\Syria_instance.xlsx', sheet_name='FoodCost', index_col='Supplier')\n",
    "df_fb = pd.read_csv('processed-data\\WFP_dataset.csv').sample(frac=1)\n",
    "bigM = 1e6\n",
    "I = pd.DataFrame(data=np.concatenate([edges['From'].drop_duplicates(), edges['To'].drop_duplicates()]), columns=['Node']).drop_duplicates()  # list of nodes\n",
    "TC = pd.DataFrame(cartesian((I['Node'], I['Node'])), columns=['From', 'To'])\n",
    "TC['tCost'] = np.ones(TC.shape[0])*bigM\n",
    "for index, row in tcost_matrix.iterrows():\n",
    "    for index1, row1 in TC.iterrows():\n",
    "        if (row['From'] == row1[0]) & (row['To'] == row1[1]):\n",
    "            TC.loc[index1, 'tCost'] = row['tCost']\n",
    "cost_t = TC.drop_duplicates()\n",
    "days = 30\n",
    "alpha = 10000  #  to convert the metric tonnes values to grams\n",
    "nodes = np.unique(TC['From'])\n",
    "df_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>OptiCL</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#3399FF'>Step 1: Conceptual Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_conceptual_model(cost_p):\n",
    "    conceptual_model = Model('WFP case study')\n",
    "\n",
    "    N = list(nutr_val.index)  # foods\n",
    "    M = nutr_req.columns  # nutrient requirements\n",
    "    \n",
    "    '''\n",
    "    Decision variables\n",
    "    '''\n",
    "    x = conceptual_model.addVars(N, vtype=GRB.CONTINUOUS, name='x', lb=0)  # variables controlling the food basket\n",
    "    f = conceptual_model.addVars(edges['From'].drop_duplicates(), edges['To'].drop_duplicates(), N, vtype=GRB.CONTINUOUS, name='flow', lb=0)\n",
    "    \n",
    "    '''\n",
    "    Objective function.\n",
    "    '''\n",
    "    conceptual_model.modelSense = GRB.MINIMIZE\n",
    "    objective = quicksum(quicksum(quicksum(f[supplier, node['To'], food]*float(cost_p.loc[supplier, food])  # procurement costs\n",
    "                                                                                        for food in N) \n",
    "                                                                                        for idx, node in edges[edges['From'] == supplier].iterrows()) \n",
    "                                                                                        for supplier in suppliers['Suppliers']) \\\n",
    "+ quicksum(quicksum(quicksum(f[node_from, node_to['To'], food]*cost_t[(cost_t['From'] == node_from) & (cost_t['To'] == node_to['To'])]['tCost'].values[0]  # Transportation costs\n",
    "                                                                                        for food in N) \n",
    "                                                                                        for idx_to, node_to in edges[edges['From'] == node_from].iterrows()) \n",
    "                                                                                        for node_from in edges['From'].drop_duplicates())\n",
    "    conceptual_model.setObjective(objective)\n",
    "    '''\n",
    "    Flow constraints.\n",
    "    '''\n",
    "    conceptual_model.addConstrs(quicksum(f[tr, node['To'], food] for idx, node in edges[edges['From'] == tr].iterrows()) == quicksum(f[node['From'], tr, food] for idx, node in edges[edges['To'] == tr].iterrows())\n",
    "                                for food in N for tr in transshippers['Transhippers'])\n",
    "    \n",
    "    conceptual_model.addConstrs(alpha*quicksum(f[node['From'], dl, food] for idx, node in edges[edges['To'] == dl].iterrows()) == demand[demand['Node'] == dl]['Demand'].values[0]*days*x[food]\n",
    "                                for food in N for dl in demand['Node'])\n",
    "\n",
    "    '''\n",
    "    Nutrients requirements constraint.\n",
    "    '''\n",
    "    conceptual_model.addConstrs(quicksum(x[food] * nutr_val.loc[food, req] for food in N) >= nutr_req[req].item() for req in M)\n",
    "    '''\n",
    "    Sugar constraint\n",
    "    '''\n",
    "    conceptual_model.addConstr(x['Sugar'] == 0.2)\n",
    "    '''\n",
    "    Salt constraint\n",
    "    '''\n",
    "    conceptual_model.addConstr(x['Salt'] == 0.05)\n",
    "    \n",
    "    return conceptual_model, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#3FCB83'>Step 2: Data Processing</font>\n",
    "The palatabily score is normalized such that we have a value between 0 and 1, where 1 is assigned to most palatable rations and 0 to the least palatable ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the palatabily score to be between 0 and 1\n",
    "def normalize(y):\n",
    "    minimum = 71.969  \n",
    "    maximum = 444.847  \n",
    "    return 1 - (y - minimum)/(maximum - minimum)\n",
    "y = df_fb['label']\n",
    "X = df_fb.drop(['label'], axis=1, inplace=False)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#CBE221'>Part 3: Learn the predictive models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1_exp'\n",
    "if question1.upper() == 'Y':\n",
    "    alg_list = ['iai','mlp', 'linear','cart','rf','svm','gbm']\n",
    "else:\n",
    "    alg_list = ['mlp', 'linear','cart','rf','svm','gbm']\n",
    "outcome_list = ['palatability']  # Constraint to be learned\n",
    "\n",
    "question2 = input('What is the palatability threshold that you want to use in the constraint? Choose in the range(0, 1): ')\n",
    "constraint_extrapolation_type = 'r'\n",
    "threshold = question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame()\n",
    "reload(ml)\n",
    "reload(ConstraintLearning)\n",
    "\n",
    "if not os.path.exists('../results/'):\n",
    "    os.makedirs('../results/')\n",
    "\n",
    "for outcome in outcome_list:\n",
    "    print(f'Learning a constraint for {outcome}')\n",
    "\n",
    "    for alg in alg_list:\n",
    "        if not os.path.exists('../results/%s/' % alg):\n",
    "            os.makedirs('../results/%s/' % alg)\n",
    "        print(f'Training {alg}')\n",
    "        s = 0\n",
    "\n",
    "        ## Run shallow/small version of RF\n",
    "        alg_run = 'rf_shallow' if alg == 'rf' else alg\n",
    "\n",
    "        m, perf = ml.run_model(X_train, y_train, X_test, y_test, alg_run, task = 'continuous', \n",
    "                               seed = s, cv_folds = 5, \n",
    "                               save = False,\n",
    "#                               parameter_grid = {'hidden_layer_sizes':[(5),(10)]}\n",
    "                              )\n",
    "\n",
    "        ## Save model\n",
    "        constraintL = ConstraintLearning.ConstraintLearning(X_train, y_train, m, alg)\n",
    "        constraint_add = constraintL.constraint_extrapolation(constraint_extrapolation_type)\n",
    "        constraint_add.to_csv('../results/%s/%s_%s_model.csv' % (alg, version, outcome), index = False)\n",
    "\n",
    "        ## Extract performance metrics\n",
    "        try:\n",
    "            perf['auc_train'] = roc_auc_score(y_train >= threshold, m.predict(X_train))\n",
    "            perf['auc_test'] = roc_auc_score(y_test >= threshold, m.predict(X_test))\n",
    "        except: \n",
    "            perf['auc_train'] = np.nan\n",
    "            perf['auc_test'] = np.nan\n",
    "\n",
    "        perf['seed'] = s\n",
    "        perf['outcome'] = outcome\n",
    "        perf['alg'] = alg\n",
    "        perf['save_path'] = '../results/%s/%s_%s_model.csv' % (alg, version, outcome)\n",
    "        \n",
    "            \n",
    "        perf.to_csv('../results/%s/%s_%s_performance.csv' % (alg, version, outcome), index = False)\n",
    "        \n",
    "        performance = performance.append(perf)\n",
    "        print()\n",
    "print('Saving the performance...')\n",
    "performance.to_csv('../results/%s_performance.csv' % version, index = False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#EA4A34'>Step 4: Predictive model selection</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_embed = ['palatability']\n",
    "objectives_embed = {}\n",
    "version = 'v1_exp'\n",
    "performance = pd.read_csv('../results/%s_performance.csv' % version)\n",
    "performance.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic selection based on measure  \n",
    "**valid_score**: r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(em)\n",
    "model_master = em.model_selection(performance, constraints_embed, objectives_embed)\n",
    "model_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints embedding and Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palatability_threshold = question2\n",
    "trust_region = input(\"Do you want to use the trust region? True/False \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master['lb'] = float(palatability_threshold)\n",
    "model_master['ub'] = None\n",
    "em.check_model_master(model_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSolution(model, X):\n",
    "    solution = {}\n",
    "    palatability = 0\n",
    "    count = 0\n",
    "    for v in model.getVars():\n",
    "        if 'x[' in v.varName:\n",
    "            solution[list(X.columns)[count]]=[v.x]\n",
    "            print(v.varName)\n",
    "            count += 1\n",
    "            \n",
    "    for v in model.getVars():\n",
    "        if 'y_palatability' == v.varName:\n",
    "            palatability = v.x\n",
    "    return solution, palatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(em)\n",
    "result = {}\n",
    "for i in range(1):\n",
    "    print(f'iter {i}')\n",
    "    np.random.seed(seed=i)\n",
    "    price_random = pd.DataFrame(np.random.random((len(suppliers), len(nutr_val)))*1000, columns=cost_p.columns, index=cost_p.index)\n",
    "    conceptual_model, x = init_conceptual_model(price_random)\n",
    "    conceptual_model.update()\n",
    "    MIP_final_model = em .optimization_MIP(conceptual_model, x, model_master, X, tr=bool(trust_region))\n",
    "    start_time = time.time()\n",
    "    MIP_final_model.Params.LogToConsole = 0\n",
    "    start_time = time.time()\n",
    "    status = MIP_final_model.optimize()\n",
    "    computation_time = time.time() - start_time    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution, result['predicted_palatability'] = getSolution(MIP_final_model, X)\n",
    "result['objective_function'] = MIP_final_model.objVal\n",
    "result['time'] = computation_time\n",
    "result['algorithm'] = model_master['model_type'].item()\n",
    "result['parameters'] = performance[performance['alg']==model_master['model_type'].item()]['best_params'].item()\n",
    "result['validation MSE'] = -performance[performance['alg']==model_master['model_type'].item()]['valid_score'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
