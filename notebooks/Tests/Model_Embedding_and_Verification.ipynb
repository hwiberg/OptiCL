{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Embedding Example and Prediction Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates how to train a single model class, embed the model, and solve the optimization problem. We fix a sample from our generated data and solve the optimization problem with all elements of $\\mathbf{x}$ equal to our data. In general, we might have some elements of $\\mathbf{x}$ that are fixed, called our \"conceptual variables,\" and the remaining indices are our decision variables. By fixing all elements of $\\mathbf{x}$, we can verify that the model prediction matches the original sklearn model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.utils.extmath import cartesian\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opticl\n",
    "from pyomo import environ\n",
    "from pyomo.environ import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data\n",
    "We will work with a basic dataset from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_regression(n_samples=200, n_features = 20, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=1)\n",
    "X_train = pd.DataFrame(X_train).add_prefix('col')\n",
    "X_test = pd.DataFrame(X_test).add_prefix('col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the chosen model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg = 'rf' \n",
    "# alg_run = 'rf_shallow'\n",
    "alg = alg_run = 'mlp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can optionally select a manual parameter grid for the cross-validation procedure. We implement a default parameter grid; see **run_MLmodels.py** for details on the tuned parameters. If you wish to use the default, leave ```parameter_grid = None``` (or do not specify any grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = None\n",
    "# parameter_grid = {'hidden_layer_sizes': [(5,),(10,)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = mlp, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 8.017082756749335e-07\n",
      "Train R2: 0.9999999999802882\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 60.24952015596481\n",
      "Test R2: 0.9987048913993389\n",
      "------------- Save results  ----------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "s = 0\n",
    "version = 'test'\n",
    "outcome = 'temp'\n",
    "\n",
    "m, perf = opticl.run_model(X_train, y_train, X_test, y_test, alg_run, task = 'continuous', \n",
    "                       seed = s, cv_folds = 5, \n",
    "                       # The user can manually specify the parameter grid for cross-validation if desired\n",
    "                       parameter_grid = parameter_grid,\n",
    "                       save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, we will save the trained model in the format needed for embedding the constraints. See **ConstraintLearning.py** for the specific format that is extracted per method. We also save the performance of the model to use in the automated model selection pipeline (if desired).\n",
    "\n",
    "We also create the save directory if it does not exist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results/%s/' % alg):\n",
    "    os.makedirs('results/%s/' % alg)\n",
    "    \n",
    "constraintL = opticl.ConstraintLearning(X_train, y_train, m, alg)\n",
    "constraint_add = constraintL.constraint_extrapolation('r')\n",
    "constraint_add.to_csv('results/%s/%s_%s_model.csv' % (alg, version, outcome), index = False)\n",
    "\n",
    "perf.to_csv('results/%s/%s_%s_performance.csv' % (alg, version, outcome), index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: what should the result be for our sample observation, if all x are fixed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose sample to test\n",
    "This will be the observation (\"patient\") that we feed into the optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 1\n",
    "sample = X_train.loc[sample_id:sample_id,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate model prediction directly in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([290.34368228])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization formulation\n",
    "We will embed the model trained above. The model could also be selected using the model selection pipeline, which we demonstrate in the WFP example script.\n",
    "\n",
    "If manually specifying the model, as we are here, the key elements of the ``model_master`` dataframe are:\n",
    "- model_type: algorithm name.\n",
    "- outcome: name of outcome of interest; this is relevant in the case of multiple learned outcomes.\n",
    "- save_path: file name of the extracted model.\n",
    "- objective: the weight of the objective if it should be included as an additive term in the objective. A weight of 0 omits it from the objective entirely.\n",
    "- lb/ub: the lower (or upper) bound that we wish to apply to the learned outcome. If there is no bound, it should be set to ``None``.\n",
    "\n",
    "In this case, we set the outcome to be our only objective term, which will allow us to verify that the predictions are consistent between the embedded model and the sklearn prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master = pd.DataFrame(columns = ['model_type','outcome','save_path','lb','ub','objective'])\n",
    "\n",
    "model_master.loc[0,'model_type'] = alg\n",
    "model_master.loc[0,'save_path'] = 'results/%s/%s_%s_model.csv' % (alg, version, outcome)\n",
    "model_master.loc[0,'outcome'] = outcome\n",
    "model_master.loc[0,'objective'] = 1\n",
    "model_master.loc[0,'ub'] = None\n",
    "model_master.loc[0,'lb'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_pyo = ConcreteModel()\n",
    "\n",
    "## We will create our x decision variables, and fix them all to our sample's values for model verification.\n",
    "N = X_train.columns\n",
    "model_pyo.x = Var(N, domain=Reals)\n",
    "\n",
    "def fix_value(model_pyo, index):\n",
    "    return model_pyo.x[index] == sample.loc[0,index]\n",
    "\n",
    "model_pyo.Constraint1 = Constraint(N, rule=fix_value)\n",
    "\n",
    "## Specify any non-learned objective components - none here \n",
    "model_pyo.OBJ = Objective(expr=0, sense=minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding objective function for temp\n"
     ]
    }
   ],
   "source": [
    "final_model_pyo = opticl.optimization_MIP(model_pyo, model_pyo.x, model_master, X_train, tr = False)\n",
    "# final_model_pyo.pprint()\n",
    "opt = SolverFactory('gurobi')\n",
    "results = opt.solve(final_model_pyo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load files for gurobipy implementation (for comparison)\n",
    "sys.path.append(os.path.abspath('../../opticl'))\n",
    "import gurobipy as grb\n",
    "import embed_mip_gurobi as em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-08-14\n",
      "Using license file /Users/hollywiberg/gurobi.lic\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 51 rows, 41 columns and 481 nonzeros\n",
      "Model fingerprint: 0xc1cf5a2a\n",
      "Variable types: 31 continuous, 10 integer (10 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 1e+05]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [7e-02, 1e+05]\n",
      "Presolve removed 51 rows and 41 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 290.344 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.903436822752e+02, best bound 2.903436822752e+02, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "model_grb = grb.Model()\n",
    "\n",
    "## We will create our x decision variables, and fix them all to our sample's values for model verification.\n",
    "N = X_train.columns\n",
    "x = model_grb.addVars(N, vtype=grb.GRB.CONTINUOUS, name='x', lb = -math.inf)\n",
    "model_grb.addConstrs(x[i] == sample.loc[0,i] for i in N)\n",
    "model_grb.update()\n",
    "final_model_grb = em.optimization_MIP(model_grb, x, model_master, X_train, tr = False)\n",
    "final_model_grb.write('test.lp')\n",
    "final_model_grb.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for equality between sklearn and embedded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True outcome: 290.344\n",
      "Gurobipy output: 290.344\n",
      "Pyomo output: 290.344\n"
     ]
    }
   ],
   "source": [
    "print(\"True outcome: %.3f\" % m.predict(sample)[0])\n",
    "print(\"Gurobipy output: %.3f\" % model_grb.ObjVal)\n",
    "print(\"Pyomo output: %.3f\" % final_model_pyo.OBJ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
