{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Embedding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates how to train a single model class, embed the model, and solve the optimization problem. We fix a sample from our generated data and solve the optimization problem with all elements of $\\mathbf{x}$ equal to our data. In general, we might have some elements of $\\mathbf{x}$ that are fixed, called our \"conceptual variables,\" and the remaining indices are our decision variables. By fixing all elements of $\\mathbf{x}$, we can verify that the model prediction matches the original sklearn model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.utils.extmath import cartesian\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opticl\n",
    "from pyomo import environ\n",
    "from pyomo.environ import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data\n",
    "We will work with a synthetic dataset using `sklearn` with three outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_regression(n_samples=500, n_features = 10,\n",
    "                       effective_rank = 5, n_targets = 3, \n",
    "                       noise = 5,\n",
    "                       random_state=2)\n",
    "\n",
    "## Add nonlinearities\n",
    "y[:,1] = y[:,1]**2 \n",
    "y[:,2] = np.log(y[:,2] - np.min(y[:,2]) + 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=1)\n",
    "X_train = pd.DataFrame(X_train).add_prefix('col')\n",
    "X_test = pd.DataFrame(X_test).add_prefix('col')\n",
    "\n",
    "y_train = pd.DataFrame(y_train).add_prefix('y')\n",
    "y_test = pd.DataFrame(y_test).add_prefix('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the chosen model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train models for each outcome and algorithm pair. \n",
    "\n",
    "The user can optionally select a manual parameter grid for the cross-validation procedure. We implement a default parameter grid; see **run_MLmodels.py** for details on the tuned parameters. If you wish to use the default, leave ```parameter_grid = None``` (or do not specify any grid).\n",
    "\n",
    "After training the model, we will save the trained model in the format needed for embedding the constraints. See **constraint_learning.py** for the specific format that is extracted per method. We also save the performance of the model to use in the automated model selection pipeline (if desired).\n",
    "\n",
    "We also create the save directory if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'test'\n",
    "outcome_list = y_train.columns\n",
    "alg_list = ['linear','rf','svm','cart','gbm','mlp'] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models for outcome: y0\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = linear, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 60.03145257380297\n",
      "Train R2: 0.021010443918817567\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 53.25623126374629\n",
      "Test R2: 0.0231403176404672\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = rf_shallow, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 23.406955342999204\n",
      "Train R2: 0.6182806872400292\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 27.500733850142886\n",
      "Test R2: 0.4955640401878698\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = svm, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 23.674785687552454\n",
      "Train R2: 0.6139129250274307\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 20.760584998338988\n",
      "Test R2: 0.6191961393843304\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 30.697324880426216\n",
      "Train R2: 0.4993897503875694\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 43.19972382648119\n",
      "Test R2: 0.20760317630881098\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = gbm, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 13.050332399896686\n",
      "Train R2: 0.7871759123739397\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 26.91508383706447\n",
      "Test R2: 0.5063064053942319\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = mlp, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 23.668038213127478\n",
      "Train R2: 0.6140229624612885\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 20.712694906684856\n",
      "Test R2: 0.6200745699193366\n",
      "------------- Save results  ----------------\n",
      "Running models for outcome: y1\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = linear, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 16684.28025355096\n",
      "Train R2: 0.0\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 15059.441538261031\n",
      "Test R2: 0.0\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = rf_shallow, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 11342.749890712192\n",
      "Train R2: 0.32015347870351896\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 16202.316750371594\n",
      "Test R2: -0.07589094251648687\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = svm, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 16589.12005033999\n",
      "Train R2: 0.005703584557728902\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 15054.042342215223\n",
      "Test R2: 0.00035852564864979897\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 14699.182897503351\n",
      "Train R2: 0.11898010138166537\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 16545.661336630685\n",
      "Test R2: -0.09869023327283832\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = gbm, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 14350.204375694464\n",
      "Train R2: 0.13989670770243323\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 15266.269774682898\n",
      "Test R2: -0.013734123931248288\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = mlp, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 6601.1777513433335\n",
      "Train R2: 0.6043474665358497\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 7700.856758666204\n",
      "Test R2: 0.48863596707083135\n",
      "------------- Save results  ----------------\n",
      "Running models for outcome: y2\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = linear, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.1806736189552282\n",
      "Train R2: 0.0\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.18403180475804223\n",
      "Test R2: 4.440892098500626e-16\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = rf_shallow, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.06917562136768246\n",
      "Train R2: 0.6171238403940726\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.1276528936316009\n",
      "Test R2: 0.3063541717724616\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = svm, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.1050272265454253\n",
      "Train R2: 0.4186908572886252\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.10353055507638513\n",
      "Test R2: 0.4374311809173258\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = cart, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.11920008819626904\n",
      "Train R2: 0.3402463022240818\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.16126919270147594\n",
      "Test R2: 0.12368846834107705\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = gbm, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.04857215363966712\n",
      "Train R2: 0.7311607863918222\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.13505654238443884\n",
      "Test R2: 0.26612390416968523\n",
      "------------- Save results  ----------------\n",
      "------------- Initialize grid  ----------------\n",
      "------------- Running model  ----------------\n",
      "Algorithm = mlp, metric = None\n",
      "------------- Model evaluation  ----------------\n",
      "-------------------training evaluation-----------------------\n",
      "Train MSE: 0.10500859265745581\n",
      "Train R2: 0.41879399292113895\n",
      "-------------------testing evaluation-----------------------\n",
      "Test MSE: 0.10324654014151263\n",
      "Test R2: 0.43897447358484\n",
      "------------- Save results  ----------------\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "\n",
    "for outcome in outcome_list:\n",
    "    print('Running models for outcome: %s' % outcome)\n",
    "    for alg in alg_list:\n",
    "        alg_run = 'rf_shallow' if alg == 'rf' else alg\n",
    "        ## Train model\n",
    "        model_save = 'results/%s/%s_%s_model.csv' % (alg, version, outcome)\n",
    "        m, perf = opticl.run_model(X_train, y_train[outcome], X_test, y_test[outcome], alg_run, \n",
    "                                   task = 'continuous', \n",
    "                                    seed = seed, \n",
    "                                    cv_folds = 5, \n",
    "                                    # The user can manually specify the parameter grid for cross-validation if desired (must match alg_run)\n",
    "                                    parameter_grid = None,\n",
    "                                    save_path = model_save,\n",
    "                                    save = False)\n",
    "        \n",
    "        ## Save model for relevant ConstraintLearning class\n",
    "        if not os.path.exists('results/%s/' % alg):\n",
    "            os.makedirs('results/%s/' % alg)\n",
    "        constraintL = opticl.ConstraintLearning(X_train, y_train, m, alg)\n",
    "        constraint_add = constraintL.constraint_extrapolation('r')\n",
    "        constraint_add.to_csv(model_save, index = False)\n",
    "\n",
    "        ## Save performance\n",
    "        perf['seed'] = seed\n",
    "        perf['outcome'] = outcome\n",
    "        perf['alg'] = alg\n",
    "        perf.to_csv('results/%s/%s_%s_performance.csv' % (alg, version, outcome), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_files = ['results/%s/%s_%s_performance.csv' % (x[0], version, x[1]) \n",
    "              for x in itertools.product(alg_list, outcome_list)]\n",
    "performance = pd.concat(pd.read_csv(x) for x in perf_files)\n",
    "performance.to_csv('results/%s_performance.csv' % version, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization formulation\n",
    "We will embed models for the outcomes using the methods trained above. The models will be selected using the model selection pipeline.\n",
    "\n",
    "The key elements of the ``model_master`` dataframe are:\n",
    "- model_type: algorithm name.\n",
    "- outcome: name of outcome of interest; this is relevant in the case of multiple learned outcomes.\n",
    "- save_path: file name of the extracted model.\n",
    "- objective: the weight of the objective if it should be included as an additive term in the objective. A weight of 0 omits it from the objective entirely.\n",
    "- lb/ub: the lower (or upper) bound that we wish to apply to the learned outcome. If there is no bound, it should be set to ``None``.\n",
    "\n",
    "In this case, we set the outcome 'y2' to be our objective term, and 'y0' and 'y1' to be constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  outcome model_type                      save_path  objective\n",
      "0      y0        svm  results/svm/test_y0_model.csv          0\n",
      "1      y1        mlp  results/mlp/test_y1_model.csv          0\n",
      "2      y2        mlp  results/mlp/test_y2_model.csv          1\n"
     ]
    }
   ],
   "source": [
    "model_master = opticl.model_selection(performance, constraints_embed = ['y0','y1'], objectives_embed = {'y2':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to set an upper or lower bound for our constrained objectives, y0 and y1. For this example, we will constrain their upper bound to be the median in the training data. 'None' indicates no constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_medians = y_train.melt().groupby('variable').median()\n",
    "model_master['lb'] = None\n",
    "model_master['ub'] = None\n",
    "model_master.loc[model_master['outcome']=='y0', 'ub'] = y_medians.loc['y0','value']\n",
    "model_master.loc[model_master['outcome']=='y1', 'ub'] = y_medians.loc['y1','value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize optimization model\n",
    "We begin by creating a base model (model_pyo) where we initialize our decision variables, fix any contextual variables, and specify domain-driven (known) constraints and objective terms.\n",
    "\n",
    "For this synthetic example, we will fix the first two values of X (col0, col1) to the observed values in the first sample. In practice, sample would specify the contextual variables (w) and their known values that the user wants to optimize for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame({'col0':[-.05],\n",
    "                      'col1':[-.05]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_pyo = ConcreteModel()\n",
    "\n",
    "## We will create our x decision variables.\n",
    "N = X_train.columns\n",
    "N_fixed = sample.columns\n",
    "model_pyo.x = Var(N, domain=Reals)\n",
    "\n",
    "## Fix the contextual features specified in 'sample'\n",
    "def fix_value(model_pyo, index):\n",
    "    return model_pyo.x[index] == sample.loc[0,index]\n",
    "\n",
    "model_pyo.add_component('constr1_fixedvals', Constraint(N_fixed, rule=fix_value))\n",
    "\n",
    "## Specify known constraints\n",
    "model_pyo.add_component('constr_known1', Constraint(expr=sum(model_pyo.x[i] for i in N) <= 1))\n",
    "\n",
    "## Specify any non-learned objective components - none here \n",
    "model_pyo.OBJ = Objective(expr=0, sense=minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating constraints for the trust region using 375 samples.\n",
      "... Trust region defined.\n",
      "Embedding constraints for y0\n",
      "Embedding constraints for y1\n",
      "Embedding objective function for y2\n"
     ]
    }
   ],
   "source": [
    "final_model_pyo = opticl.optimization_MIP(model_pyo, model_pyo.x, model_master, X_train, tr = True)\n",
    "# final_model_pyo.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SolverFactory('gurobi')\n",
    "results = opt.solve(final_model_pyo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value: 2.505\n",
      "\n",
      "X values: \n",
      "Feature col0: value = -0.050\n",
      "Feature col1: value = -0.050\n",
      "Feature col2: value = -0.035\n",
      "Feature col3: value = -0.026\n",
      "Feature col4: value = 0.011\n",
      "Feature col5: value = -0.010\n",
      "Feature col6: value = -0.014\n",
      "Feature col7: value = 0.033\n",
      "Feature col8: value = 0.042\n",
      "Feature col9: value = 0.001\n",
      "\n",
      "Lambda values (convex hull weights): \n",
      "Observation 0: weight = 0.658\n",
      "Observation 47: weight = 0.217\n",
      "Observation 122: weight = 0.053\n",
      "Observation 163: weight = 0.072\n"
     ]
    }
   ],
   "source": [
    "print(\"Objective value: %.3f\" % final_model_pyo.OBJ())\n",
    "\n",
    "print(\"\\nX values: \")\n",
    "x_sol = getattr(final_model_pyo, 'x')\n",
    "for index in N:\n",
    "    val = x_sol[index].value\n",
    "    print(\"Feature %s: value = %.3f\" % (index, val))\n",
    "    \n",
    "print(\"\\nLambda values (convex hull weights): \")\n",
    "lambda_sol = getattr(final_model_pyo, 'lam')\n",
    "for index in lambda_sol:\n",
    "    val = lambda_sol[index].value\n",
    "    if val != 0:\n",
    "        print(\"Observation %s: weight = %.3f\" % (index, val))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
